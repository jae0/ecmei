#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass paper
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding utf8
\fontencoding global
\font_roman "times" "default"
\font_sans "helvet" "default"
\font_typewriter "courier" "default"
\font_math "newtxmath" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks false
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks true
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref section
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip bigskip
\is_math_indent 0
\math_numbering_side default
\quotes_style plain
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Spatiotemporal models of variability
\end_layout

\begin_layout Author
Jae S.
 Choi
\end_layout

\begin_layout Institution
Population Ecology Division, Fisheries and Oceans Canada, Bedford Institute
 of Oceanography
\end_layout

\begin_layout Address
1 Challenger Drive, Dartmouth, Nova Scotia, Canada
\end_layout

\begin_layout Standard
Version: 09/24/2018
\end_layout

\begin_layout Abstract
A review of continuous models of spatiotemporal variability in a fisheries
 oceanography context.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Ecological and biological processes demonstrate variability in space and
 in time.
 Characterizing and understanding this variability is necessary to understand
 the generative processes.
 Sampling design tries to approach such issues by trying to balance information
 obtained vs costs of sampling.
 Strategies can range from completely random sampling in the absence of
 additional information, to some form of stratified random or even blocked
 designs that randomly chooses samples from strata constrained by factors
 believed to be pertinent or informative or at least one tries to abstract
 away as 
\begin_inset Quotes qld
\end_inset

background variability
\begin_inset Quotes qrd
\end_inset

.
 A common one is of course areal stratification based upon some prior knowledge
 that is known or believed to be informative (e.g., depth, temperature or
 some oceanic feature), such that the variability within strata will be
 smaller than that between strata.
 The lower the variability within strata (relative to between-strata variability
), the better the stratification of spatial areas (
\begin_inset Quotes eld
\end_inset

design
\begin_inset Quotes erd
\end_inset

) has captured local homogeneities in the process of interest (e.g., abundance
 of some organism); that is, each sample is thought to be more representative
 of the stratum that it represents.
 
\end_layout

\begin_layout Standard
The problem of course is that the size of these strata can shrink to unmanageabl
e numbers as the number of informative factors increase and the kinds of
 processes also increase.
 Further, the locations of such strata can shift if they are based upon
 features that are not geographically fixed, such as with temperature, oxygen
 levels, abundance of prey or predators, light levels, etc.
 The fixed area approach, therefore, crudely 
\begin_inset Quotes eld
\end_inset

adjusts
\begin_inset Quotes erd
\end_inset

 for the influence of these 
\begin_inset Quotes eld
\end_inset

extraneous
\begin_inset Quotes erd
\end_inset

 factors by re-weighting of the total variance such that they can, thereafter,
 be ignored.
 These factors, are however, also highly informative and ignoring them for
 the sake of simplicity by 
\begin_inset Quotes eld
\end_inset

factoring them out
\begin_inset Quotes erd
\end_inset

 can lead to erroneous conclusions about the focal process(es) of interest,
 especially when they are dynamic.
 
\end_layout

\begin_layout Standard
There exist two main approaches attempting to incorporate such additional
 information: (1) a spatially continuous process and (2) spatially aggregated
 areal units.
 Both approaches decompose the spatial patterns into those that are associated
 with 1) informative factors; 2) structured spatial autocorrelation patterns;
 and 3) completely spatially unstructured errors.
 In the following, we will summarize the general background to the field,
 and focus upon the spatially continuous case, following closely Banerjee
 et al.' s (2004) exceptionally clear and thorough exposition.
 To assist in the context of stock assessment and general spatial and spatiotemp
oral modeling of potentially large areas, some of these methods have been
 formulated in an R-package, 
\begin_inset Quotes eld
\end_inset


\series bold
stmv
\series default

\begin_inset Quotes erd
\end_inset

 (https://github.com/jae0/stmv).
 This document will also serve to document these methods.
 The spatially aggregated case will be treated in a separate followup document
 (or appended to this document in some future iteration).
 
\end_layout

\begin_layout Section
Continuous representation
\end_layout

\begin_layout Subsection
Spatial autocorrelation
\end_layout

\begin_layout Standard
To be precise, we focus upon any spatially referenced observation 
\begin_inset Formula $Y_{s}$
\end_inset

 at locations 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $s$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
, measured in a coordinate space whose domain 
\begin_inset Formula $D$
\end_inset

 has dimensionality 
\begin_inset Formula $d$
\end_inset

 such that 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $\{\mathbf{\text{s}}\in D\in\Re^{d}\}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
.
 We focus upon the simple case of 
\begin_inset Formula $d=2$
\end_inset

 spatial dimensions, such that for example, 
\begin_inset Formula $s=(\text{northing, easting})$
\end_inset

.
 The observations 
\begin_inset Formula $Y_{s}$
\end_inset

 are assumed to be realizations of a 
\series bold
spatial stochastic process
\series default
, 
\begin_inset Formula $y$
\end_inset

, that is some latent unobservable but real, stochastic, generative 
\series bold
function
\series default
 (i.e., a spatial random field) such that 
\begin_inset Formula $y_{s}\rightarrow Y_{s}$
\end_inset

 at {
\begin_inset Formula $k=1,\dots,K$
\end_inset

} spatial locations.
 The manner in which the variability of 
\begin_inset Formula $y_{s}$
\end_inset

 changes as a function of distance, 
\begin_inset Formula $h=\parallel s-s'\parallel$
\end_inset

, is known as the spatial autocorrelation function.
 The 
\begin_inset Formula $\parallel\cdot\parallel$
\end_inset

 indicates a spatial norm which in 
\begin_inset Formula $d=2$
\end_inset

 spatial dimensions is simply the Euclidean distance, 
\begin_inset Formula $h=(\Delta\text{northing}^{2}+\Delta\text{easting}^{2})^{1/2}$
\end_inset

.
 
\end_layout

\begin_layout Standard
The spatial model is expressed as a regression model of a stochastic process
 (Banerjee et al.
 2004):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
g(Y_{s})=\boldsymbol{x}_{s}^{T}\boldsymbol{\boldsymbol{\beta}}+\omega_{s}+\varepsilon_{s},\label{eq:basic_spatial_model}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where, the observations 
\begin_inset Formula $Y_{s}$
\end_inset

 are realizations of some mean process 
\begin_inset Formula $\boldsymbol{x}_{s}^{T}\boldsymbol{\boldsymbol{\beta}}$
\end_inset

 (sometimes referred to as 
\begin_inset Quotes eld
\end_inset

external drift
\begin_inset Quotes erd
\end_inset

 in the kriging literature), and a residual error process 
\begin_inset Formula $(\omega_{s}+\varepsilon_{s})$
\end_inset

, operating potentially under the context of Generalized Linear Models via
 the link function 
\begin_inset Formula $g(\cdot)$
\end_inset

.
 The 
\begin_inset Formula $x_{s}$
\end_inset

 are spatially referenced predictors with associated parameters 
\series bold

\begin_inset Formula $\boldsymbol{\beta}$
\end_inset


\series default
.
 The residual error process is decomposed into spatially structured 
\begin_inset Formula $\omega_{s}$
\end_inset

 and spatially unstructured 
\begin_inset Formula $\varepsilon_{s}$
\end_inset

 components, both with mean of zero.
 The latter is also commonly called the 
\begin_inset Quotes eld
\end_inset

nugget
\begin_inset Quotes erd
\end_inset

 error in geostatistics and used to represent measurement and/or microscale
 variability/processes; it is usually assumed to have a Normal distribution
 and standard deviation 
\begin_inset Formula $\sigma_{\varepsilon}$
\end_inset

.
 The spatial error is assumed to follow a 
\series bold
Gaussian process
\series default
 with mean 0 and a spatial covariance function 
\begin_inset Formula $C(s,s';\theta)$
\end_inset

 that describes form of the variance of the process as a function of distance
 between data, controlled by the parameters 
\begin_inset Formula $\theta$
\end_inset

 and spatially structured standard deviation 
\begin_inset Formula $\sigma_{\omega}$
\end_inset

 (see below).
 The full model specification is, therefore: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{matrix}g(Y_{s}) & = & \boldsymbol{x}_{s}^{T}\boldsymbol{\boldsymbol{\beta}}+\omega_{s}+\varepsilon_{s},\\
\varepsilon_{s} & \sim & \text{N}(0,\sigma_{\varepsilon}^{2}),\\
\omega_{s} & \sim & \text{GP}(\boldsymbol{0},C(s,s';\theta)).
\end{matrix}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The above is equivalent to assuming a Multivariate Normal likelihood for
 the observations 
\begin_inset Formula $\mathbf{Y}=(Y_{s_{1}},\ldots,Y_{s_{K}})^{T}$
\end_inset

, with mean 
\begin_inset Formula $\boldsymbol{\mu}=g(\mathbf{Y})=\left[x_{\text{s}_{i}}^{T}\right]_{i=1}^{K}\boldsymbol{\beta}$
\end_inset

 and a covariance matrix 
\begin_inset Formula $\boldsymbol{\mathbf{\Sigma}}=\left[C(\text{s}_{i},\text{s}_{j};\theta)\right]_{i,j=1}^{K}+\tau^{2}I_{K}$
\end_inset

, such that 
\begin_inset Formula $\mathbf{Y}\sim\text{MVN}(\boldsymbol{\mu},\boldsymbol{\Sigma})$
\end_inset

; with 
\begin_inset Formula $I_{K}$
\end_inset

 an identity matrix of size 
\begin_inset Formula $K$
\end_inset

.
 It is also computationally more efficient as fewer likelihood evaluations
 are conducted and fast and sparse implementations of the Multivariate Normal
 exist.
\end_layout

\begin_layout Standard
The spatial covariance function 
\begin_inset Formula $C(h)=C(s,s';\theta)$
\end_inset

 expresses the tendency of observations closer together to be more similar
 to each other than those further away.
 Commonly used forms include:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{matrix}C(h)_{\text{Spherical}} & = & \left\{ \begin{matrix}\sigma_{s}^{2}(1-\frac{3}{2}h/\phi+\frac{1}{2}(h/\phi)^{3}); & 0<h<=\phi\\
0; & h>\phi,
\end{matrix}\right.\\
C(h)_{\text{Exponential}} & = & \sigma_{s}^{2}e^{-h/\phi},\\
C(h)_{\text{Gaussian}} & = & \sigma_{s}^{2}e^{-(h/\phi)^{2}},\\
C(h)_{\text{Powered exponential}} & = & \sigma_{s}^{2}e^{-|h/\phi|^{p}},\\
C(h)_{\text{Matérn}} & = & \sigma_{s}^{2}\frac{1}{2^{\nu-1}\Gamma(\nu)}(\sqrt{2\nu}h/\phi)^{\nu}\ K_{\nu}(\sqrt{2\nu}h/\phi).
\end{matrix}\label{eq:covar_funcs}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
At zero distance, 
\begin_inset Formula $C(0)=\text{Cov}(Y_{s},Y_{s})=\text{Var}(Y_{s})=\sigma_{\varepsilon}^{2}+\sigma_{s}^{2}$
\end_inset

 (
\emph on
i.e.
\emph default
, global variance), where 
\begin_inset Formula $\sigma_{\varepsilon}$
\end_inset

 is the nonspatial, unstructured error, 
\begin_inset Formula $\sigma_{s}$
\end_inset

 is the spatially structured error, and 
\begin_inset Formula $\theta=\{\phi,\nu,p,\ldots\}$
\end_inset

 are function-specific parameters including 
\begin_inset Formula $\phi$
\end_inset

 the 
\emph on
range
\emph default
 parameter.
 
\begin_inset Formula $\Gamma(\cdot)$
\end_inset

 is the Gamma function and 
\begin_inset Formula $K_{\nu}(\cdot)$
\end_inset

 is the Bessel function of the second kind with smoothness 
\begin_inset Formula $\nu$
\end_inset

.
 The Matérn covariance function is frequently used in the more recent literature
 as the shape of this function is more flexible (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:autocorrelation"

\end_inset

).
\end_layout

\begin_layout Standard
\begin_inset CommandInset label
LatexCommand label
name "fig:autocorrelation"

\end_inset


\begin_inset Graphics
	filename autocorrelation.png
	lyxscale 50
	scale 10

\end_inset


\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:autocorrelation"

\end_inset

: Matérn autocorrelation function, 
\begin_inset Formula $\rho(h)=C(h)/C(0)$
\end_inset

, the covariance function 
\begin_inset Formula $C(h)$
\end_inset

 scaled by the total variance 
\begin_inset Formula $C(0)$
\end_inset

, for two values of 
\begin_inset Formula $\nu$
\end_inset

 (dark lines).
 As 
\begin_inset Formula $\nu$
\end_inset

 increases 
\begin_inset Formula $(\nu=100)$
\end_inset

, it approaches the Gaussian curve (upper dark curve on the left side) while
 at smaller values 
\begin_inset Formula $(\nu=0.5)$
\end_inset

 the curve is exponential (lower dark curve on the left side).
 This flexibility has made it a popular choice in geostatistics.
 The associated semivariograms (scaled to unit variance) 
\begin_inset Formula $\gamma(h)$
\end_inset

 are shown in light stippled lines.
 Spatial scale is defined heuristically as the distance 
\begin_inset Formula $h$
\end_inset

 at which the autocorrelation falls to 0.05 (dashed horizontal line)– in
 this example between 2.5 and 3 distance units, depending upon value of 
\begin_inset Formula $\nu$
\end_inset

.
 The semivariance (also called 
\begin_inset Quotes eld
\end_inset

semivariogram
\begin_inset Quotes erd
\end_inset

) 
\begin_inset Formula $\gamma(h)$
\end_inset

, is more commonly used in the kriging literature, and is simply the covariance
 function 
\begin_inset Formula $C(h)$
\end_inset

 reflected on the horizontal axis of the global variance 
\begin_inset Formula $C(0)$
\end_inset

 such that 
\begin_inset Formula $\gamma(h)=C(0)-C(h)=\frac{1}{2}\ \text{Var}[Y_{s}-Y_{s}']=\sigma_{\omega}^{2}[1-\rho(h)]$
\end_inset

.
 
\end_layout

\begin_layout LyX-Code
\begin_inset Note Note
status open

\begin_layout LyX-Code
#------------------ ## plot of matern covariance 
\end_layout

\begin_layout LyX-Code
phi = 1 
\end_layout

\begin_layout LyX-Code
sigma = 1 
\end_layout

\begin_layout LyX-Code
nu = 0.5 
\end_layout

\begin_layout LyX-Code
x = seq(0, 4, by=0.1) 
\end_layout

\begin_layout LyX-Code
matern.covariance = function( sigma, nu, phi, x) {    
\end_layout

\begin_layout LyX-Code
  1/(2^(nu-1)*gamma(nu) ) 
\end_layout

\begin_layout LyX-Code
  * (sqrt(2*nu)*x/phi)^nu * besselK(sqrt(2*nu)*x/phi, nu) 
\end_layout

\begin_layout LyX-Code
} 
\end_layout

\begin_layout LyX-Code
y = matern.covariance( sigma, nu, phi, x) 
\end_layout

\begin_layout LyX-Code
plot( y~x, type="l", ylim=c(0,1.1) ) 
\end_layout

\begin_layout LyX-Code
nu = 100 y100 = matern.covariance( sigma, nu, phi, x) 
\end_layout

\begin_layout LyX-Code
lines( x,y100 ) 
\end_layout

\begin_layout LyX-Code
text ( 0.3*max(x), 0.9, "nu=100 ~ Gaussian" ) 
\end_layout

\begin_layout LyX-Code
text ( 0.2*max(x), 0.2, "nu=0.5 ~ Exponential" ) 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
Defining the spatial scale of a given observation or process is imperative
 for the development of any ecological assessment or monitoring.
 The 
\series bold
spatial autocorrelation function
\series default
 is defined as the covariance function scaled by the global variance: 
\begin_inset Formula $\rho(h)=C(h)/C(0)$
\end_inset

.
 Heuristically, we define the 
\series bold
spatial autocorrelation scale
\series default
 to be the distance at which the spatial autocorrelation decreases asymptoticall
y to 
\begin_inset Formula $\rho(x)\rightarrow0.05$
\end_inset

 (occasionally called the 
\begin_inset Quotes eld
\end_inset

practical
\begin_inset Quotes erd
\end_inset

 range in the literature).
 This spatial scale of an ecological process is informative in that when
 short-range processes dominate relative to the scale of the whole domain,
 such as when focusing upon less mobile species, weakly dispersing, low
 currents, habitat heterogeneity, then monitoring these processes can be
 meaningful and fruitful in discriminating what is structuring an area of
 interest.
 If, however, long-ranging processes dominate relative to the scale of the
 whole domain, such as when focusing upon higher mobility species or dispersal
 processes/current, and stronger spatial connectivity, habitat heterogeneity,
 then there is a lower likelihood that monitoring such processes will provide
 insights to the internal structure of the area of interest.
 
\end_layout

\begin_layout Standard
This is perhaps clearest when spatial scale is studied in the context of
 specific organisms.
 For example, when a spatial feature (e.g., abundance distribution in space)
 demonstrates short characteristic spatial scales (i.e., a lot of spatial
 variability at smaller scales), sampling approaches must respect this and
 similarly operate at such shorter scales or even smaller if one is to be
 able to resolve the patterns and describe properly the subject of interest.
 Similarly, if a spatial feature is long-ranged and one wishes to resolve
 the patterns properly, then a sampling protocol must be similarly long-ranged
 to resolve the pattern.
 A sampling program much smaller than the characteristic spatial scale would
 be beneficial, but the accrued benefits relative to cost of sampling would
 diminish rapidly, in that time, effort and resources requirements generally
 increase more rapidly than any benefit (e.g., in the simplest case, if one
 is looking only naively at standard error as a measure of benefit, then
 it would increase asymptotically with increased effort with a power of
 
\begin_inset Formula $-1/2$
\end_inset

).
\end_layout

\begin_layout Section
Temporal autocorrelation
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
 see https://onlinecourses.science.psu.edu/stat510 for a nice summary
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Ecological systems also exist in a temporal frame.
 As such, similar to the above spatial considerations, there also exists
 some characteristic temporal scale upon which the processes internal to
 an area of interest and time period of interest operate.
 The canonical example is how some quantity changes from one discrete-time
 period to another.
 This discrete-time notion of temporal autocorrelation is the slope parameter
 from a plot of a variable as a function of itself with an offset of one
 time unit: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\upsilon_{t+1}=\rho\upsilon_{t}+\eta_{t},
\]

\end_inset


\end_layout

\begin_layout Standard
with 
\begin_inset Formula $\eta_{t}\sim N(0,\sigma_{t}^{2})$
\end_inset

 and a temporal (linear) autocorrelation parameter 
\begin_inset Formula $\rho$
\end_inset

.
 This is known as an AR(1) process, where the 1 indicates 1 unit time lag.
 More complex models with moving averages and additional time-lags can also
 be specified.
 Collectively these are known as AR, ARMA, and ARIMA models.
 The difficulty with these autocorrelation timeseries formulations is the
 requirement of a complete data series without missing data.
 
\end_layout

\begin_layout Standard
The 
\series bold
cumulative periodogram
\series default
 expresses the variance 
\begin_inset Formula $f(\omega$
\end_inset

) as a function of temporal distance (wavelengths 
\begin_inset Formula $\omega$
\end_inset

) and so is an analogue of the spatial semivariogram.
 It is a discrete sample estimate of the continuous concept of spectral
 density, 
\begin_inset Formula $\gamma(t)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{ccc}
\gamma(t)=\int_{-1/2}^{1/2}e^{2\pi i\omega t}f(\omega)d\omega & \longleftrightarrow & f(\omega)=\sum_{h=-\infty}^{h=\infty}\gamma(t)e^{-2\pi i\omega t}.\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
Usefully, as the autocovariance and spectral density are Fourier transform
 pairs, a Fast Fourier Transform can be used to rapidly assess the power
 spectrum and determine the empirical form of the periodogram.
 This also of course in classical usage faces the same requirement of a
 complete data series without missing data.
 However, when used as the temporal analogue of an empirical spatial covariance
 generating 
\series bold
stochastic process
\series default
, it remains useful as a first order descriptive tool of the error processe.
 Indeed, any spatial autocorrelation function can be used to describe the
 empirical form of the temporal autocorrelation pattern and modeled in a
 manner completely analogous to the spatial case as a 
\series bold
temporal stochastic process
\series default
, 
\begin_inset Formula $y_{t}$
\end_inset

, that is, some latent, unobservable but real, stochastic, generative 
\series bold
function
\series default
 such that 
\begin_inset Formula $y_{t}\rightarrow Y_{t}$
\end_inset

, where 
\begin_inset Formula $Y_{t}$
\end_inset

 are any temporally referenced observation at some time 
\begin_inset Formula $t$
\end_inset

, measured in a coordinate space whose domain 
\begin_inset Formula $D$
\end_inset

 has dimensionality 1 such that 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $\{t\in D\in\Re\}$
\end_inset

 with 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit

\begin_inset Formula $\{l=1,\dots,L\}$
\end_inset

 temporal locations.
 The manner in which the variability of 
\begin_inset Formula $Y_{t}$
\end_inset

 changes as a function of the norm (distance), 
\begin_inset Formula $h=\parallel t-t'\parallel$
\end_inset

, is known as the temporal autocorrelation function.
 The latter can take any form including the same as the spatial autocorrelation
 functions.
 The model formulation is identical to the spatial case:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{matrix}g(Y_{t}) & = & \boldsymbol{x}_{t}^{T}\boldsymbol{\beta}+\omega_{t}+\varepsilon_{t},\\
\varepsilon_{t} & \sim & \text{N}(0,\sigma_{\varepsilon}^{2}),\\
\omega_{t} & \sim & \text{GP}(\boldsymbol{0},C(t,t';\theta)).
\end{matrix}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The covariance function, for example, when expressed as an exponential decay
 model controlled by time range parameter 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $\phi_{t}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
C(t,t';\theta_{t})=\sigma_{t}^{2}e^{-|h|/\phi_{t}}.
\]

\end_inset


\end_layout

\begin_layout Standard
Similar to the case of spatial scales, temporal scales also have a simple
 implication in terms of monitoring and assessment.
 Short time-range variations require higher sampling effort to resolve/understan
d the issues and vice-versa.
 As temporal scale is an informative metric for monitoring and assessment
 of an ecological process, we must be precise in its definition.
 The cumulative distribution permits a rapid identification of the time
 scale at which correlation drops to some arbitrary level.
 To be approximately comparable to the spatial scale, we define the 
\series bold
temporal autocorrelation scale
\series default
 as the time difference (wavelength) at which the temporal autocorrelation
 function (1 - Cumulative Power Spectral Density) decreases to 5% of the
 total variance.
 If resolving short-term processes is a study's goal, then sampling must
 also necessarily be more frequent.
 However, similar to spatial scale issues, there is a point where there
 will be diminishing returns for any increase in the resolution of a temporal
 signal.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Subsubsection
(Aside) Background: 
\end_layout

\begin_layout Plain Layout
(copied from https://onlinecourses.science.psu.edu/stat510/node/80)
\end_layout

\begin_layout Plain Layout
The autocovariance and spectral density are Fourier transform pairs.
 We won’t worry about the calculus of the situation.
 We’ll focus on the estimation of the spectral density – the frequency domain
 characterization of a series.
 The Fourier transform equations are only given here to establish that there
 is a direct link between the time domain representation and the frequency
 domain representation of a series.
\end_layout

\begin_layout Plain Layout
Mathematically, the spectral density is defined for both negative and positive
 frequencies.
 However, due to symmetry of the function and its repeating pattern for
 frequencies outside the range -1/2 to +1/2, we only need to be concerned
 with frequencies between 0 and +1/2.
\end_layout

\begin_layout Plain Layout
The “total” integrated spectral density equals the variance of the series.
 Thus the spectral density within a particular interval of frequencies can
 be viewed as the amount of the variance explained by those frequencies.
\end_layout

\begin_layout Plain Layout
Methods for Estimating the Spectral Density
\end_layout

\begin_layout Plain Layout
The raw periodogram is a rough sample estimate of the population spectral
 density.
 The estimate is “rough”, in part, because we only use the discrete fundamental
 harmonic frequencies for the periodogram whereas the spectral density is
 defined over a continuum of frequencies.
\end_layout

\begin_layout Plain Layout
One possible improvement to the periodogram estimate of the spectral density
 is to smooth it using centered moving averages.
 An additional “smoothing” can be created using tapering methods which weight
 the ends (in time) of the series less than the center of the data.
 We’ll not cover tapering in this lesson.
 Interested parties can see Section 4.5 in the book and various Internet
 sources.
\end_layout

\begin_layout Plain Layout
An alternative approach to smoothing the periodogram is a parametric estimation
 approach based on the fact that any stationary time series can be approximated
 by an AR model of some order (although it might be a high order).
 In this approach a suitable AR model is found, and then the spectral density
 is estimated as the spectral density for that estimated AR model.
\end_layout

\begin_layout Plain Layout
Smoothing Method (Nonparametric Estimation of the Spectral Density)
\end_layout

\begin_layout Plain Layout
The usual method for smoothing a periodogram has such a fancy name that
 it sounds difficult.
 In fact, it’s merely a centered moving average procedure with a few possible
 modifications.
 For a time series, the Daniell kernel with parameter m is a centered moving
 average which creates a smoothed value at time t by averaging all values
 between times t – m and t +m (inclusive).
 For example, the smoothing formula for a Daniell kernel with m = 2 is
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\hat{x}_{t}=\frac{x_{t-2}+x_{t-1}+x_{t}+x_{t+1}+x_{t+2}}{5}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
In R, the weighting coefficients for a Daniell kernel with m = 2 can be
 generated with the command kernel("daniell", 2).
 The result is
\end_layout

\begin_layout Plain Layout
coef[-2] = 0.2 coef[-1] = 0.2 coef[ 0] = 0.2 coef[ 1] = 0.2 coef[ 2] = 0.2
\end_layout

\begin_layout Plain Layout
The subscripts for coef [ ] refer to the time difference from the center
 of the average at time t.
 Thus the smoothing formula in this instance is
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\hat{x}_{t}=0.2x_{t-2}+0.2x_{t-1}+0.2x_{t}+0.2x_{t+1}+0.2x_{t+2},
\]

\end_inset


\end_layout

\begin_layout Plain Layout
which is the same as the formula given above.
\end_layout

\begin_layout Plain Layout
The modified Daniell kernel is such that the two endpoints in the averaging
 receive half the weight that the interior points do.
 For a modified Daniell kernel with m = 2, the smoothing is
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\hat{x}_{t}=\frac{x_{t-2}+2x_{t-1}+2x_{t}+2x_{t+1}+x_{t+2}}{8}=0.125x_{t-2}+0.25x_{t-1}+0.25x_{t}+0.25x_{t+1}+0.125x_{t+2}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
In R, the command kernel("modified.daniell", 2) will list the weighting coefficie
nts just used.
\end_layout

\begin_layout Plain Layout
Either the Daniell kernel or the modified Daniell kernel can be convoluted
 (repeated) so that the smoothing is applied again to the smoothed values.
 This produces a more extensive smoothing by averaging over a wider time
 interval.
 For instance, to repeat a Daniell kernel with m = 2 on the smoothed values
 that resulted from a Daniell kernel with m = 2, the formula would be
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\hat{\hat{x}}_{t}=\frac{\hat{x}_{t-2}+\hat{x}_{t-1}+\hat{x}_{t}+\hat{x}_{t+1}+\hat{x}_{t+2}}{5}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
This is the average of the smoothed values within two time periods of time
 t, in either direction.
\end_layout

\begin_layout Plain Layout
In R, the command kernel("daniell",c(2,2)) will supply the coefficients
 that would be applied to as weights in averaging the original data values
 for a convoluted Daniell kernel with m = 2 in both smoothings.
 The result is
\end_layout

\begin_layout Plain Layout
> kernel ("daniell",c(2,2)) 
\end_layout

\begin_layout Plain Layout
coef[-4] = 0.04 coef[-3] = 0.08 coef[-2] = 0.12 coef[-1] = 0.16 coef[ 0] = 0.20
 coef[ 1] = 0.16 coef[ 2] = 0.12 coef[ 3] = 0.08 coef[ 4] = 0.04
\end_layout

\begin_layout Plain Layout
This generates the smoothing formula
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\hat{x}_{t}=0.04x_{t-4}+0.08x_{t-3}+0.12x_{t-2}+0.16x_{t-1}+0.20x_{t}+0.16x_{t+1}+0.12x_{t+2}+0.08x_{t+3}+0.04x_{t+4}.
\]

\end_inset


\end_layout

\begin_layout Plain Layout
A convolution of the modified method in which the end points have less weight
 is also possible.
 The command 
\end_layout

\begin_layout Plain Layout
kernel("modified.daniell",c(2,2)) gives these coefficients:
\end_layout

\begin_layout Plain Layout
coef[-4] = 0.01563 coef[-3] = 0.06250 coef[-2] = 0.12500 coef[-1] = 0.18750
 coef[ 0] = 0.21875 coef[ 1] = 0.18750 coef[ 2] = 0.12500 coef[ 3] = 0.06250
 coef[ 4] = 0.01563
\end_layout

\begin_layout Plain Layout
Thus the center values are weighted slightly more heavily than in the unmodified
 Daniell kernel.
\end_layout

\begin_layout Plain Layout
When we smooth a periodogram, we are smoothing across a frequency interval
 rather than a time interval.
 Remember that the periodogram is determined at the fundamental frequencies
 
\begin_inset Formula $\omega_{j}=j/n$
\end_inset

 for
\begin_inset Formula $j=1,2,\cdots,n/2$
\end_inset

.
 Let 
\begin_inset Formula $I(\omega_{j})$
\end_inset

 denote the periodogram value at frequency 
\begin_inset Formula $\omega_{j}=j/n$
\end_inset

.
 When we use a Daniell kernel with parameter m to smooth a periodogram,
 the smoothed value 
\begin_inset Formula $\hat{I}(\omega_{j})$
\end_inset

 is a weighted average of periodogram values for frequencies in the range
 
\begin_inset Formula $(j-m)/n$
\end_inset

 to 
\begin_inset Formula $(j+m)/n$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Bandwidth
\end_layout

\begin_layout Plain Layout
There are 
\begin_inset Formula $L=2m+1$
\end_inset

 fundamental frequency values in the range 
\begin_inset Formula $(j-m)/n$
\end_inset

 to 
\begin_inset Formula $(j+m)/n$
\end_inset

, the range of values used for smoothing.
 The bandwidth for the smoothed periodogram is defined as
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
B_{\omega}=\frac{L}{n}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
The bandwidth is a measure of the width of the frequency interval(s) used
 for smoothing the periodogram.
\end_layout

\begin_layout Plain Layout
When unequal weights are used in the smoothing, the bandwidth definition
 is modified.
 Denote the smoothed periodogram value at 
\begin_inset Formula $\omega_{j}=j/n$
\end_inset

 as
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\hat{I}(\omega_{j})=\sum_{k=-m}^{+m}h_{k}I\left(\omega_{j}+\frac{k}{n}\right).
\]

\end_inset


\end_layout

\begin_layout Plain Layout
The 
\begin_inset Formula $h_{k}$
\end_inset

 are the possibly unequal weights used in the smoothing.
 The bandwidth formula is then modified to
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
B_{\omega}=\frac{L_{h}}{n}=\frac{1/\sum h_{k}^{2}}{n}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Actually, this formula works for equal weights too.
\end_layout

\begin_layout Plain Layout
The bandwidth should be sufficient to smooth our estimate, but if we use
 a bandwidth that is too great, we’ll smooth out the periodogram too much
 and miss seeing important peaks.
 In practice, it usually takes some experimentation to find the bandwidth
 that gives a suitable smoothing.
\end_layout

\begin_layout Plain Layout
The bandwidth is predominately controlled by the number of values that are
 averaged in the smoothing.
 In other words, the m parameter for the Daniell kernel and whether the
 kernel is convoluted (repeated) affect the bandwidth.
\end_layout

\begin_layout Plain Layout
Note: The bandwidths R reports with its plots don’t match the values that
 would be calculated using the formulas above.
 Please see the footnote on p.
 197 of your text for an explanation.
\end_layout

\begin_layout Plain Layout
R Code
\end_layout

\begin_layout Plain Layout
Averaging/smoothing the periodogram with a Daniell kernel can be accomplished
 in R using a sequence of two commands.
 The first defines a Daniell kernel and the second creates the smoothed
 periodogram.
\end_layout

\begin_layout Plain Layout
As an example, suppose that the observed series is named x and we wish to
 smooth the periodogram using a Daniell kernel with m = 4.
 The commands are
\end_layout

\begin_layout Plain Layout
k = kernel("daniell", 4) 
\end_layout

\begin_layout Plain Layout
spec.pgram(x, k, taper=0, log = "no")
\end_layout

\begin_layout Plain Layout
The first command creates the weighting coefficients needed for the smoothing
 and stores them in a vector named k.
 (It’s arbitrary to call it k.
 It could be called anything.) The second command asks for a spectral density
 estimate based on the periodogram for the series x, using the weighting
 coefficients stored in k, with no taper, and the plot will be on an ordinary
 scale, not a log scale.
\end_layout

\begin_layout Plain Layout
If a convolution is desired, the kernel command could be modified to something
 like k = kernel("daniell", c(4,4)).
\end_layout

\begin_layout Plain Layout
There are two possible ways to achieve a modified Daniell kernel.
 You can either change the kernel command to refer to the “modified.daniell”
 rather than “daniell” or you can skip using the kernel command and use
 a spans parameter in the spec.pgram command.
\end_layout

\begin_layout Plain Layout
The spans parameter gives the length (=2m+1) of the desired modified Daniell
 kernel.
 For instance, a modified Daniell kernel with m = 4 has length L = 2m+1
 = 9 so the we could use the command
\end_layout

\begin_layout Plain Layout
spec.pgram(x, spans=9, taper = 0, log="no")
\end_layout

\begin_layout Plain Layout
Two passes of a modified Daniell kernel with m = 4 on each pass can be done
 using
\end_layout

\begin_layout Plain Layout
spec.pgram(x, spans=c(9,9), taper = 0, log="no")
\end_layout

\begin_layout Plain Layout
Example: This example will use the fish recruitment series that’s used in
 several places in the text, including several places in chapter 4.
 The series consists of n = 453 monthly values of a measure of a fish population
 in a southern hemisphere location.
 The data are in the file recruit.dat.
\end_layout

\begin_layout Plain Layout
The raw periodogram can be created using the command (or it could be created
 using the method given in Lesson 6).
\end_layout

\begin_layout Plain Layout
spec.pgram(x, taper=0, log="no")
\end_layout

\begin_layout Plain Layout
Note that in the command just given we have omitted the parameter that gives
 weights for smoothing.
\end_layout

\begin_layout Plain Layout
The raw periodogram follows:
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
The next plot is a smoothed periodogram using a Daniell kernel with m =
 4.
 Note that one effect of the smoothing is that the dominant peak in the
 unsmoothed version is now the second tallest peak.
 This happened because the peak is so sharply defined in the unsmoothed
 version that when we average it with a few surrounding values the height
 is reduced.
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
The next plot is a smoothed periodogram using two passes of a Daniell kernel
 with m = 4 on each pass.
 Note how it is even more smoothed than previously.
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
To learn where the two dominant peaks are located, assign a name to the
 spec.pgram output and then you can list it.
 For instance,
\end_layout

\begin_layout Plain Layout
specvalues = spec.pgram(x, k, taper=0, log="no") specvalues
\end_layout

\begin_layout Plain Layout
You can sift through the output to find the frequencies at which the peaks
 occur.
 The frequencies and spectral density estimates are listed separately, but
 in the same order.
 Identify the maximum spectral densities and then find the corresponding
 frequencies.
\end_layout

\begin_layout Plain Layout
Here, the first peak is at a frequency ≈ .0229.
 The period (number of months) associated with this cycle = 1/.0229 = 43.7
 months, or about 44 months.
 The second peak occurs at a frequency ≈ 0.083333.
 The associated period = 1/.08333 = 12 months.
 The first peak is associated with an El Nino weather effect.
 The second is the usual 12 month seasonal effect.
\end_layout

\begin_layout Plain Layout
These two commands will put vertical dotted lines onto the (estimated) spectral
 density plot at the approximate locations of the peak densities.
\end_layout

\begin_layout Plain Layout
abline(v=1/44, lty="dotted") abline(v=1/12, lty = "dotted")
\end_layout

\begin_layout Plain Layout
Here’s the resulting plot:
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
We’ve smoothed enough, but for demonstration purposes, the next plot is
 the result of
\end_layout

\begin_layout Plain Layout
spec.pgram(x, spans=c(13,13), taper=0, log="no")
\end_layout

\begin_layout Plain Layout
This uses two passes of a modified Daniell kernel with length L = 13 (so
 m = 6) each time.
 The plot is a bit smoother, but not by much.
 The peaks, by the way, are in exactly the same places as in the plot immediatel
y above.
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
It’s definitely possible to smooth too much.
 Suppose that we were to use a modified Daniell kernel of total length =
 73 (m = 36).
 The command is
\end_layout

\begin_layout Plain Layout
spec.pgram(x, spans=73, taper=0, log="no")
\end_layout

\begin_layout Plain Layout
The result follows.
 The peaks are gone!
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
Parametric Estimation of the Spectral Density
\end_layout

\begin_layout Plain Layout
The smoothing method of spectral density estimation is called a nonparametric
 method because it doesn’t use any parametric model for the underlying time
 series process.
 An alternative method is a parametric method which entails finding the
 best fitting AR model for the series and then plotting the spectral density
 of that model.
 This method is supported by a theorem which says that the spectral density
 of any time series process can be approximated by the spectral density
 of an AR model (of some order, possibly a high one).
\end_layout

\begin_layout Plain Layout
In R, parametric estimation of the spectral density is easily done with
 the command/function spec.ar.
 A command like spec.ar(x, log="no") will cause R to do all of the work.
 Again, to identify peaks we can assign a name to the spec.ar results by
 doing something like specvalues=spec.ar(x, log ="no").
\end_layout

\begin_layout Plain Layout
For the fish recruitment example, the following plot is the result.
 Note that the density plotted is that of an AR(13) model.
 We can certainly find more parsimonious ARIMA models for these data.
 We’re just using the spectral density of that model to approximate the
 spectral density of the observed series.
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
The appearance of the estimated spectral density is about he same as before.
 The estimated El Nino peak is located at a slightly different place – the
 frequency is about 0.024 for a cycle of about 1/.024 = about 42 months.
\end_layout

\begin_layout Subsubsection
De-trending
\end_layout

\begin_layout Plain Layout
A series should be de-trended prior to a spectral analysis.
 A trend will cause such a dominant spectral density at a low frequency
 that other peaks won’t be seen.
 By default, the R command spec.pgram performs a de-trending using a linear
 trend model.
 That is, the spectral density is estimated using the residuals from a regressio
n done where the y-variable = observed data and the x-variable = t.
 If a different type of trend is present, a quadratic for instance, then
 a polynomial regression could be used to de-trend the data before the estimated
 spectral density is explored.
 Note, however, that the R command spec.ar, however does not perform a de-trendin
g by default.
\end_layout

\begin_layout Plain Layout
Application of Smoothers to Raw Data
\end_layout

\begin_layout Plain Layout
Note that the smoothers described here could also be applied to raw data.
 The Daniell kernel and its modifications are simply moving average (or
 weighted moving average) smoothers.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Spatiotemporal autocorrelation
\end_layout

\begin_layout Standard
In reality, spatial and temporal patterns coexist and co-evolve.
 They are correlated processes and as such a challenge to model properly.
 This renders the independent treatment and estimation of autocorrelation
 in time and space problematic.
 Nonetheless, new developments in computational methods are bringing such
 models within range of use.
 This is primarily due to efficient methods associated with numerical modeling
 of Stochastic Partial Differential Equations (SPDEs), and the use of spectral
 (Fourier) methods.
\end_layout

\begin_layout Standard
Again, following Banerjee et al.'s (2004) development, spatiotemporal models
 can be seen as a simple extension of the spatial regression model.
 The observations, 
\begin_inset Formula $Y_{s,t}$
\end_inset

 are measured in a coordinate space 
\begin_inset Formula $\{(s,t)\in D\in\mathfrak{R}^{d}\mathfrak{\times R}\}$
\end_inset

 in the domain 
\begin_inset Formula $D$
\end_inset

 of dimensionality 
\begin_inset Formula $d+1$
\end_inset

 with {
\begin_inset Formula $k=1,\dots,K$
\end_inset

} spatial and 
\begin_inset Formula $\{l=1,\dots,L\}$
\end_inset

 temporal locations.
 The space-time regression model can then be specified as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
g(Y_{s,t})=\boldsymbol{x}_{s,t}^{T}\boldsymbol{\beta}_{s,t}+\omega_{s,t}+\varepsilon_{s,t},
\]

\end_inset


\end_layout

\begin_layout Standard
where, 
\begin_inset Formula $\boldsymbol{x}_{s,t}^{T}\boldsymbol{\beta}_{s,t}$
\end_inset

 is the mean process (or 
\begin_inset Quotes eld
\end_inset

external drift
\begin_inset Quotes erd
\end_inset

 in the kriging literature) and the error process is decomposed into a spatiotem
porally structured component 
\begin_inset Formula $\omega$
\end_inset

 and an unstructured component 
\begin_inset Formula $\varepsilon$
\end_inset

, operating again under a generalized linear model framework, through the
 action of the link function 
\begin_inset Formula $g(\cdot)$
\end_inset

.
 The parameters 
\begin_inset Formula $\boldsymbol{\beta}_{s,t}$
\end_inset

 of the spatially and temporally referenced predictors 
\begin_inset Formula $\boldsymbol{x}_{s,t}$
\end_inset

 can have variable forms:
\end_layout

\begin_layout Itemize
\begin_inset Formula $\boldsymbol{\beta}$
\end_inset

 – completely fixed with no variation in time and space;
\end_layout

\begin_layout Itemize
\begin_inset Formula $\boldsymbol{\beta}_{-,t}$
\end_inset

 – temporally varying and no spatial structure;
\end_layout

\begin_layout Itemize
\begin_inset Formula $\boldsymbol{\beta}_{s,-}$
\end_inset

– spatially varying and no temporal structure;
\end_layout

\begin_layout Itemize
\begin_inset Formula $\beta_{s,-}\circledcirc\beta_{-,t}$
\end_inset

 – space and time varying independently (separably, the 
\begin_inset Quotes qld
\end_inset


\begin_inset Formula $\circledcirc$
\end_inset


\begin_inset Quotes qrd
\end_inset

 indicates additive or multiplicative);
\end_layout

\begin_layout Itemize
\begin_inset Formula $\boldsymbol{\beta}_{s,t}$
\end_inset

– varying in both time and space complex (nonseparable) and potentially
 hierarchically (nonsimply).
\end_layout

\begin_layout Standard
The 
\emph on
unstructured
\emph default
 error is usually assumed to be a Normal 
\emph on
iid
\emph default
 error process: 
\begin_inset Formula $\varepsilon_{s,t}\sim N(0,\sigma_{\varepsilon}^{2})$
\end_inset

.
 However, the manner in which the 
\emph on
spatiotemporally structured
\emph default
 error should be parameterized is not straight-forward.
 Some common approaches include:
\end_layout

\begin_layout Itemize
\begin_inset Formula $\omega_{-,t}$
\end_inset

 – temporal effects nested in sites (temporal autocorrelation at each site,
 no spatial autocorrelation);
\end_layout

\begin_layout Itemize
\begin_inset Formula $\omega_{s,-}$
\end_inset

 – spatial effects nested in time (spatial autocorrelation at each time
 slice, no temporal autocorrelation);
\end_layout

\begin_layout Itemize
\begin_inset Formula $\omega_{s,-}\circledcirc\omega_{-,t}$
\end_inset

 – 
\emph on
separable
\emph default
 (spatial and temporal autocorrelations are independent, the 
\begin_inset Quotes qld
\end_inset


\begin_inset Formula $\circledcirc$
\end_inset


\begin_inset Quotes qrd
\end_inset

 indicates additive or multiplicative) with 
\begin_inset Formula $\omega_{-,t}\sim\text{GP}(\boldsymbol{0},C(\boldsymbol{\text{t}},\boldsymbol{\text{t}}';\theta_{t}))$
\end_inset

 and 
\begin_inset Formula $\omega_{s,-}\sim\text{GP}(\boldsymbol{0},C(\mathbf{s},\mathbf{s}';\theta_{s}))$
\end_inset

;
\end_layout

\begin_layout Itemize
\begin_inset Formula $\omega_{s,t}$
\end_inset

 – non-separable (both time and space structure evolve in a nonsimple manner).
 
\end_layout

\begin_layout Standard
If the spatial and temporal errors are assumed to be derived from a 
\series bold
Gaussian Process
\series default
 with mean 0 and some covariance 
\begin_inset Formula $C(\cdot,\cdot;\mathbf{\theta})$
\end_inset

, then the spatial covariance can be modeled with a flexible form such as
 the Matérn:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
C(\Delta s)_{\text{Matérn}}=\sigma_{s}^{2}\frac{1}{2^{\nu-1}\Gamma(\nu)}(\sqrt{2\nu}|\Delta s|/\phi)^{\nu}\ K_{\nu}(\sqrt{2\nu|}\Delta s|/\phi).
\]

\end_inset

 
\end_layout

\begin_layout Standard
Similarly, the temporal covariance can be formulated as any reasonable autocorre
lation model such as for example the exponential: 
\begin_inset Formula $C(\Delta t)_{\text{Exponential}}=\sigma_{t}^{2}e^{-|\Delta t|/\phi_{t}}$
\end_inset

.
 
\end_layout

\begin_layout Standard
While conceptually coherent and elegant, the evaluation of the likelihoods
 in theses models requires the repeated computation of the inverse of the
 covariance matrix 
\begin_inset Formula $\Sigma_{n\times n}$
\end_inset

 of size n, an operation that scales with 
\begin_inset Formula $\mathcal{O}(n^{3})$
\end_inset

 operations.
 This has been a bottleneck to further development and use of these covariance-b
ased methods in large scaled problems of space and space-time.
 Approximations have been suggested to overcome this computational limit:
 modeling the spatial process 
\begin_inset Formula $\omega$
\end_inset

 with a lower dimensional process via kernel convolutions, moving averages,
 low rank splines/basis functions and predictive processes (projection of
 spatial process onto a smaller subset; Sølna and Switzer 1996, Wikle and
 Cressie 1999, Hung et al.
 2004, Xu et al.
 2005, Banerjee et al.
 2004); approximating the spatial process as a Markov random field with
 Laplace and SPDE Approximations (Lindgren and Rue 2015); and approximating
 the likelihood of the spatial-temporal SPDE process with a spectral domain
 process (Sigrist et al.
 2012).
\end_layout

\begin_layout Standard
In the spatiotemporal setting, separable models are almost always used for
 the sake of computational speed as this treats space and time independently,
 reducing the problems crudely from 
\begin_inset Formula $\mathcal{O}((KL)^{3})$
\end_inset

 to 
\begin_inset Formula $\mathcal{O}(K^{3})+\mathcal{O}(L^{3})$
\end_inset

 operations; where 
\begin_inset Formula $K$
\end_inset

 is the number of spatial locations and 
\begin_inset Formula $L$
\end_inset

 the number of time slices.
 In reality, however, such separable models are usually inappropriate unless
 the study area is homogeneous and truly first and second order constant
 (i.e., constant mean, variance) across both time and space, a fact that is
 seldom true in most ecological systems (see below).
 
\end_layout

\begin_layout Standard
A central assumption of all spatial and spatiotemporal models is that the
 form and magnitude of the autocorrelation in space and usually also in
 time are second order stationary (constant mean and variance).
 This can be forced to be the case by modeling the mean effects and operating
 upon a residual error that is stationary.
 However, in practice, there is spatial heterogeneity of variance as well
 which cannot be easily modeled in a simple regression context.
 This is notoriously the case with biology where aggregation and behavior
 is highly clustered and context (location and time) dependent (nonlinear).
 
\end_layout

\begin_layout Section
Spatiotemporal models of variability (stmv)
\end_layout

\begin_layout Standard
In 
\series bold
stmv
\series default
, this 
\series bold
nonstationarity
\series default
 and 
\series bold
nonseparability
\series default
 of spatial and temporal structure and associated issues of computational
 speed and complexity is addressed by formulating a simple, operational
 approach to the overall spatiotemporal problem.
 This is done by reducing the problem into small manageable subdomains where
 assumptions of stationary are valid and modeling of spatiotemporal processes
 and associated parameters become computationally feasible and supported
 by data in the subdomain.
 There is, therefore, some conceptual similarity of this approach to 
\begin_inset Quotes eld
\end_inset

geographically weighted regression
\begin_inset Quotes erd
\end_inset

 (e.g., Fotheringham et al.
 2002) in that each subdomain can have their own model parameters, 
\begin_inset Formula $\beta_{s,t}$
\end_inset

.
 However, geographically weighted regression permit only the model parameters
 
\begin_inset Formula $\beta_{s,t}$
\end_inset

 to vary; in contrast, 
\series bold
stmv
\series default
 permits both the model parameters 
\begin_inset Formula $\beta_{s,t}$
\end_inset

 and the spatiotemporal errors 
\begin_inset Formula $\varphi_{s,t}$
\end_inset

 to vary.
 
\end_layout

\begin_layout Standard
To be more precise, in the spatiotemporal domain 
\begin_inset Formula $D$
\end_inset

, where 
\begin_inset Formula $\{(s,t)\in D\in\mathfrak{R}^{d}\mathfrak{\times R|}d=2\}$
\end_inset

 defines the coordinate space, we define statistical nodes 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\{N_{m=(1,\dots,M)}|m\in\mathfrak{R}^{d}\}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit
 in a spatial lattice (or conceivably as centroids of a mesh, though this
 is not yet implemented; Figure 5.1).
 The norm (distance) of data from each node is 
\begin_inset Formula $h_{m}=||s_{m},s_{Y}||$
\end_inset

.
 A local subdomain of a given node 
\begin_inset Formula $m$
\end_inset

 is 
\begin_inset Formula $\{S_{m=(1,\dots,M)}\in D|h_{m}<h_{u}\}$
\end_inset

 or more briefly as 
\begin_inset Formula $S_{m}$
\end_inset

 which represents all locations within some distance to the statistical
 node 
\begin_inset Formula $\{h_{u}|C(h_{u})_{\text{Matérn}}=0.05\}$
\end_inset

; that is, the distance at which the local spatial autocorrelation drops
 to a negligible value (arbitrarily taken as 
\begin_inset Formula $p<0.05$
\end_inset

) and associated parameter values are 
\begin_inset Quotes qld
\end_inset

supported
\begin_inset Quotes qrd
\end_inset

.
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
The data found within the subdomain 
\begin_inset Formula $m$
\end_inset

 is 
\begin_inset Formula $\{Y_{s,t}|(s,t)\in D|h_{m}<h_{u}\}$
\end_inset

 is notationally abbreviated as 
\begin_inset Formula $Y_{s,t|m}$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename concept1.pdf
	lyxscale 50
	scale 25

\end_inset


\end_layout

\begin_layout Standard
Figure 5.1 Spatial distribution of data (blue dots) overlaid by a statistical
 grid in 
\series bold
stmv
\series default
.
 The 
\begin_inset Formula $m$
\end_inset

 nodes represent the centers of each local subdomain 
\begin_inset Formula $S_{m}$
\end_inset

 which extends to a distance (right-facing arrows; solid circles) that varies
 depending upon the underlying spatial variability of the data and is defined
 in 
\series bold
stmv 
\series default
as the distance at which the spatial autocorrelation drops to some small
 value (
\begin_inset Formula $p<0.05$
\end_inset

).
 Data within this distance and parameters obtained from the local analysis
 are used to complete the local model of the spatial or spatiotemporal processes
 and then predict/interpolate to some fraction of the local spatial range
 (default is 75%; down-facing arrow, stippled circle).
 Every statistical node is visited with many overlapping predictions that
 are locally averaged (weighted by number of predictions and prediction
 variance).
 As grid size decreases the number of models increases.
 This also reduces computation load and RAM requirements.
 However, the utility of the model also declines due to small sample sizes
 entering analyses.
 Judicious choice of statistical grid density as well as maximum and minimum
 number of data points and upper and lower bounds of spatial bounds must
 be balanced.
 This balancing has not been made automatic (yet).
 
\end_layout

\begin_layout Standard
Operating upon all components of the regression model simultaneously is
 computationally prohibitive.
 Even with very simplistic Generalized Additive Model (GAM) or Generalized
 Additive Mixed effects Model (GAMM) parameterizations of spatial and temporal
 structure, the solutions take many days/weeks on fast machines (5 GHz CPU,
 64GB RAM in 2016), depending of course upon the amount of data and resolution
 and model complexity.
 As a compromise between model complexity and computational speed, 
\series bold
stmv
\series default
 uses a global covariate model 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $F(\cdot)\equiv\boldsymbol{x}_{s,t}^{T}\boldsymbol{\beta}_{s,t}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 parameterized using a linear, generalized linear or generalized additive
 model.
 Here, 
\begin_inset Formula $F(\cdot)$
\end_inset

 represents some potential penalized basis splines of low order (3 knots
 or less seem biologically plausible when modality can be expected) of the
 covariate predictors and potentially some function 
\begin_inset Formula $g(\cdot)$
\end_inset

 that represents a link function such that the residual error in the link-space
 can be assumed to be Normal with mean zero and standard deviation 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $\sigma_{\varphi}$
\end_inset

, the latter 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
accounting for the residual error process 
\begin_inset Formula $\varphi_{s,t}$
\end_inset

:
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}g(Y_{s,t}) & = & F(\cdot)+\varphi_{s,t},\\
\varphi_{s,t} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
The spatiotemporal structure is decomposed from this residual error process
 and so the approach is in fact quite similar to 
\begin_inset Quotes eld
\end_inset

regression kriging
\begin_inset Quotes erd
\end_inset

 and (universal) 
\begin_inset Quotes eld
\end_inset

kriging with external drift
\begin_inset Quotes erd
\end_inset

 (Hengl et al.
 2004).
 
\end_layout

\begin_layout Standard
The local spatial autocorrelation scale is derived from a rapid (coarse
 grained) fit of the local residuals 
\begin_inset Formula $\varphi_{s,t|m}$
\end_inset

 to a Matérn autocorrelation function.
 To be symmetrical in time, one would also need to determine temporal nodes
 and define appropriate temporal autocorrelation scales.
 In practice, temporal data are often sparse and limiting in survey data
 and so data from all time periods are used, essentially amounting to a
 temporally averaged spatial autocorrelation.
 Once the approximate bounds of the subdomain (support) are estimated, the
 
\begin_inset Formula $\varphi_{s,t|m}$
\end_inset

 are modeled as some function 
\begin_inset Formula $f_{m}(\cdot)\equiv\boldsymbol{\varphi}_{s,t|m}^{T}\boldsymbol{\beta}_{s,t|m}$
\end_inset

 of a Fourier series with two harmonics, one interannual and one subannual
 (seasonal): 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $f_{m}(\text{interannual, seasonal})$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
.
 In other words, a full temporal autocorrelation (covariance) model is not
 used but rather one that uses only a subset of the components at fixed
 wavelengths:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}\varphi_{s,t|m} & = & f_{m}(\cdot)+\zeta_{s,t|m},\\
\zeta_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\zeta|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
Data are (optionally) weighted by the inverse squared distance 
\begin_inset Formula $h_{m}^{-2}$
\end_inset

 from the coordinates of each statistical node 
\begin_inset Formula $m$
\end_inset

 to make data closer to the area of interest and prediction more influential.
 The temporal autocorrelation is, therefore, carried by the individual temporal
 processes at each spatial datum and the temporally structured error 
\begin_inset Formula $\sigma_{t|m}$
\end_inset

 is the variance component of the model 
\begin_inset Formula $f_{m}(\cdot)$
\end_inset

, that is, 
\begin_inset Formula $\sigma_{t|m}=\text{Var}[\varphi_{s,t|m}]-\sigma_{\zeta|m}^{2}$
\end_inset

.
 
\end_layout

\begin_layout Standard
The spatial autocorrelation function is parameterized as being derived from
 the subdomain mean Gaussian process with a Matérn covariance function with
 parameters 
\begin_inset Formula $\theta_{m}=\{\phi_{m},\nu_{m}\}$
\end_inset

 and a time-varying 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
spatially structured standard error 
\begin_inset Formula $\sigma_{s|m}$
\end_inset

.
 As the data used to estimate the spatial autocorrelation structure are
 often sparse, the data are augmented by temporal predictions of the residual
 error process at each spatial datum (and notationally designated by an
 asterisk).
 These temporally 
\begin_inset Quotes qld
\end_inset

augmented
\begin_inset Quotes qrd
\end_inset

 residual processes are modeled spatially at each time slice 
\begin_inset Formula $\varphi_{s,t|m}^{*}$
\end_inset

 as the sum of a time-varying spatial
\series bold
 Gaussian process
\series default
 
\begin_inset Formula $\omega_{s,t|m}$
\end_inset

 parameterized as a Matérn spatial covariance function 
\begin_inset Formula $\sigma_{s,t|m}^{2}\frac{1}{2^{\nu_{t|m}-1}\Gamma(\nu_{t|m})}(\sqrt{2\nu_{t|m}}h/\phi_{t|m})^{\nu_{t|m}}\ K_{\nu_{t|m}}(\sqrt{2\nu_{t|m}}h/\phi_{t|m})$
\end_inset

 with a local spatial error 
\series medium

\begin_inset Formula $\sigma_{s,t|m}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
; and a spatially and temporally unstructured error process assumed to be
 derived from a Normal error process with mean zero and error 
\begin_inset Formula $\sigma_{\varepsilon|m}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}\varphi_{s,t|m}^{*} & = & \omega_{s,t|m}+\varepsilon_{s,t|m},\\
\omega_{s,t|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{t|m}=\{\nu_{t|m},\phi_{t|m},\sigma_{t|m}\})),\\
\varepsilon_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
The current approach represents a practical balance between computational
 time and model complexity/realism.
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
For additional speed, an FFT-based Matérn convolution implementation is
 used.
 
\end_layout

\begin_layout Standard
As 
\series bold
stmv
\series default
 focuses upon prediction using a mosaic of solutions in space, overall likelihoo
d or AIC evaluation is a challenge.
 At present, predictive success is the only means to evaluate utility and
 eventually some form of Expectation-Maximization approaches might be fruitful,
 once computational speeds improve.
 A fully Bayesian approach is being considered that removes the need to
 work with 
\begin_inset Quotes qld
\end_inset

external drift
\begin_inset Quotes qrd
\end_inset

 and facilitates global model evaluation.
 However, this approach is also awaiting increased computational power.
 These and other more flexible and complex models can be defined in this
 modular framework and they will be expanded upon in future versions of
 this document.
 
\end_layout

\begin_layout Standard
To facilitate usage and mapping of 
\series bold
stmv
\series default
 to other domains, the data handling methods and model parameterizations
 are encoded in a separate R-library,
\series bold
 aegis 
\series default
which can be found at http://github.com/jae0/aegis.
\end_layout

\begin_layout Section
Using stmv
\end_layout

\begin_layout Standard
The stmv library depends upon a number of important R-packages.
 The full list is: alphahull, bigmemory, devtools, ff, fields, gstat, geoR,
 lattice, lubridate, mgcv, mvtnorm, parallel, sp, rgdal, RandomFields, RandomFie
ldsUtils, truncnorm.
 It also uses the aegis, aegis.env packages which are found only on github.
 The latter two optionally uses raster, maps, mapdata, ROracle.
 Most dependencies should be pulled in automatically, but there may need
 to be some manual intervention.
 By default, bigmemory is used as a storage engine to facilitate parallel
 operations.
 In Linux, the use of parallel operations through MPI or socket communication
 is well established, in MacOS and MSWindows, it is not certain and so one
 may be forced to use local cores only.
 In using 
\series bold
stmv 
\series default
in clusters, one must be careful of the amount of communications overhead
 especially when large data volumes are involved.
 Your mileage will vary.
 For most usage, local-core operations should be sufficient.
\end_layout

\begin_layout Standard
The following is the primary call to the library:
\end_layout

\begin_layout Quotation

\size scriptsize
stmv::stmv( p=p, runmode="interpolate" )
\end_layout

\begin_layout Standard
Other 
\begin_inset Quotes qld
\end_inset

runmode
\begin_inset Quotes qrd
\end_inset

 values exist, but they are primarily for debugging and testing purposes.
 All functionally is really controlled through the options in the parameter
 list 
\begin_inset Quotes qld
\end_inset

p
\begin_inset Quotes qrd
\end_inset

.
 Most of the defaults options work well and should only be altered if absolutely
 necessary.
 The more user-modifiable options are listed in the examples below with
 explanations.
 
\end_layout

\begin_layout Subsection
Example 1: pure spatial models of bathymetry and substrate grainsize
\end_layout

\begin_layout Standard
As some oceanographic features change on geological time scales, we can
 treat them as a pure spatial problem, though of course, in reality they
 are not truly static.
 Bathymetry (depth; m) is one such feature that is highly informative in
 that it determines ambient light levels, surface complexity/rugosity, hydrodyna
mic stability and overall environmental stability.
 
\end_layout

\begin_layout Standard
In 
\series bold
aegis
\series default
, it is modeled as a Lognormal process using 
\series bold
stmv
\series default
:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}\text{log}(Y_{s}) & = & F(\text{constant offset})+\varphi_{s},\\
\varphi_{s} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}),\\
\varphi_{s|m} & = & \omega_{s|m}+\varepsilon_{s|m},\\
\omega_{s|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{m}=\{\nu_{m},\phi_{m},\sigma_{m}\})),\\
\varepsilon_{s|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
As it is a pure space model, there is no need to temporally 
\begin_inset Quotes eld
\end_inset

augment
\begin_inset Quotes erd
\end_inset

 the data leaving a direct decomposition of the global residual error process
 
\begin_inset Formula $\varphi_{s|m}$
\end_inset

 into a local spatial process 
\begin_inset Formula $\omega_{s|m}$
\end_inset

 and a local unstructured error 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $\varepsilon_{s|m}$
\end_inset

.
 An FFT-based Matérn convolution implementation is used to express the spatial
 process for computational speed improvements.
 
\end_layout

\begin_layout Standard
The above model is formulated as follows:
\end_layout

\begin_layout Quotation

\size scriptsize
p = list( 
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
stmv_dimensionality="space", # spatial process on ..
 no need for temporal components
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_Y_transform =list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
transf = function(x) {x + 2000} ,
\end_layout

\begin_layout Quotation

\size scriptsize
invers = function(x) {x - 2000}
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
), # data range is from -1667 to 5467 m: make all positive valued to make
 lognormal better behaved
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelengine = "glm", # basic glm is used to operate on lognormal
 space 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelformula = formula(z ~ 1), # constant with log gaussian
 making it a lognormal model, really just to get to link space
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_family = gaussian(link="log"), # lognormal
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_modelengine="fft",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_fft_filter = "lowpass_spatial.process", # act as a low pass filter first
 before matern ..
 depth has enough data for this
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_lowpass_phi = 0.5, # low pass FFT filter range ..
 0.5 seems to be optimal (by visual inspection)
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_lowpass_nu = 0.5, # this makes it ~ exponential covariance
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_statsgrid = 5, # resolution (km) of data aggregation (i.e.
 generation of the ** statistics ** )
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_scale = 30, # km ...
 approx guess of 95% AC range
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_max = 60,
\end_layout

\begin_layout Quotation

\size scriptsize
n.min = 400, # min number of data points req before attempting to model timeserie
s in a localized space
\end_layout

\begin_layout Quotation

\size scriptsize
n.max = 8000 # no real upper bound..
 just speed
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
)
\end_layout

\begin_layout Standard
The core model specification is as above.
 Other parameters are, however, required to operate with data inputs and
 locations for results output, etc.
 To facilitate this, 
\series bold
aegis
\series default
 takes care of a lot of the details.
 
\end_layout

\begin_layout Quotation

\size scriptsize
p = aegis::aegis_parameters( 
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
DS = "bathymetry", 
\end_layout

\begin_layout Quotation

\size scriptsize
data_root = project.datadirectory( "aegis", "bathymetry" ), 
\end_layout

\begin_layout Quotation

\size scriptsize
DATA = 'bathymetry.db( p=p, DS="stmv.inputs" )', 
\end_layout

\begin_layout Quotation

\size scriptsize
spatial.domain = c( "canada.east.superhighres" ), 
\end_layout

\begin_layout Quotation

\size scriptsize
spatial.domain.subareas = c( "canada.east.superhighres", "canada.east.highres",
 "canada.east", "SSE", "SSE.mpa" , "snowcrab"), 
\end_layout

\begin_layout Quotation

\size scriptsize
pres_discretization_bathymetry = 1 / 100, # 1==p$pres; controls resolution
 of data prior to modeling (km ..
 ie 100 linear units smaller than the final discretization pres) 
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
) 
\end_layout

\begin_layout Quotation

\size scriptsize
# this adds additional options related to data sources, etc.
\end_layout

\begin_layout Standard

\size scriptsize
# and then run with:
\end_layout

\begin_layout Quotation

\size scriptsize
stmv( p=p, runmode=c( "globalmodel", "interpolate" ) ) # This will take
 from 40-70 hrs, depending upon system 
\end_layout

\begin_layout Standard
Once complete, wrapping functions exist within 
\series bold
aegis 
\series default
to assimilate the results and continue with analysis and figure generation:
\end_layout

\begin_layout Quotation

\size scriptsize
aegis::bathymetry.db( p=p, DS="complete.redo" ) # finalise 
\end_layout

\begin_layout Standard
Similarly, substrate grain size (mm) is a pure space model which is a proxy
 measure of the type of substrate (mud, sand, gravel, rock, etc.) and so
 informative for benthic, demersal and infaunal habitat.
 Unfortunately, the only available data is an (over-)smoothed surface provided
 by Kostylev and Hannah (2007) and not the source data.
 Some data have been added from the snow crab surveys.
 It is also modeled as a Lognormal process and an FFT spatial process implementa
tion of the Matérn covariance:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}\text{log}(Y_{s}) & = & F(\text{depth, slope, curvature})+\varphi_{s},\\
\varphi_{s} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}),\\
\varphi_{s|m} & = & \omega_{s|m}+\varepsilon_{s|m},\\
\omega_{s|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{m}=\{\nu_{m},\phi_{m},\sigma_{m}\})),\\
\varepsilon_{s|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
This model is parameterized as:
\end_layout

\begin_layout Quotation

\size scriptsize
ram_required_main_process = 3 # GB
\end_layout

\begin_layout Quotation

\size scriptsize
ram_required_per_process = 2 # GB in 2017, approximate upper bound, usually
 2-4 GB/process
\end_layout

\begin_layout Quotation

\size scriptsize
ncpu = min( parallel::detectCores(), floor( (ram_local()-ram_required_main_proce
ss) / ram_required_per_process ) )
\end_layout

\begin_layout Quotation

\size scriptsize
p = aegis::aegis_parameters(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
DS = "substrate",
\end_layout

\begin_layout Quotation

\size scriptsize
data_root = project.datadirectory( "aegis", "substrate" ),
\end_layout

\begin_layout Quotation

\size scriptsize
spatial.domain = c( "canada.east.highres"),
\end_layout

\begin_layout Quotation

\size scriptsize
spatial.domain.subareas = c( "canada.east.highres", "canada.east", "SSE", "snowcrab",
 "SSE.mpa" ),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_dimensionality="space",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelengine = "gam",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelformula = formula( paste(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
'substrate.grainsize ~ s( b.sdTotal, k=3, bs="ts") + s(log(z), k=3, bs="ts")
 ',
\end_layout

\begin_layout Quotation

\size scriptsize
'+s(log(dZ), k=3, bs="ts") +s(log(ddZ), k=3, bs="ts") + s(log(b.range), k=3,
 bs="ts")') ), # a GAM model 
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
stmv_global_family = gaussian(link="log"),
\end_layout

\begin_layout Quotation

\size scriptsize
# a log-normal works ok but a model of log-transformed data works better
 ..
 ie, working upon medians which is really OK
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_modelengine="fft", # currently the preferred approach
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_lowpass_phi = 1*2, # p$res *2 = 1 *2:: FFT based method when operating
 globally
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_lowpass_nu = 0.5, # this is exponential covar
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_variogram_method = "gstat",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_eps = 0.001, # distance units for eps noise to permit mesh gen for boundarie
s
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_rsquared_threshold = 0.1, # lower threshold
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_statsgrid = 5, # resolution (km) of data aggregation (i.e.
 generation of the ** statistics ** )
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_scale = 40, # km ...
 approx guess of 95% AC range
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_max = 80,
\end_layout

\begin_layout Quotation

\size scriptsize
sampling = c( 1, 4/3, 5/3 ), # fractions of distance scale and n.min to try
 when insufficient data are found
\end_layout

\begin_layout Quotation

\size scriptsize
depth.filter = 0.1, # the depth covariate is input in m, so, choose stats
 locations with elevation > 0 m as being on land
\end_layout

\begin_layout Quotation

\size scriptsize
n.min = 400, # n.min/n.max changes with resolution
\end_layout

\begin_layout Quotation

\size scriptsize
n.max = 4000, # numerical time/memory constraint -- anything larger takes
 too much time ..
 anything less ..
 errors
\end_layout

\begin_layout Quotation

\size scriptsize
clusters=rep("localhost", ncpu ))
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
)
\end_layout

\begin_layout Quotation

\size scriptsize
stmv( p=p, runmode=c("globalmodel", "interpolate" ) ) # no global_model
 and force a clean restart
\end_layout

\begin_layout Quotation

\size scriptsize
substrate.db( p=p, DS="complete.redo" ) # gather results
\end_layout

\begin_layout Subsection
Example 2: inseparable spatiotemporal model of temperature
\end_layout

\begin_layout Standard
Temperature is a fundamentally important to metabolism, growth, reproduction,
 predator and prey distribution and abundance, and disease incidence.
 Bottom temperatures, in particular, are the focus due to their relevance
 to benthic and demersal organisms and modeled as an hierarchical, spatiotempora
l, 
\begin_inset Quotes eld
\end_inset

inseparable
\begin_inset Quotes erd
\end_inset

 spatiotemporal process.
 As their variations have high frequency variations, some additional complexity
 is required in modeling their spatiotemporal variations.
 Here, the temporal effects are nested in spatial subdomains 
\begin_inset Formula $S_{m}$
\end_inset

.
 The global covariate model is simply an intercept model with an identity
 link such that 
\begin_inset Formula $\varphi_{s,t}$
\end_inset

 are centered upon zero.
 Salinity or water density data can conceivably enter to delineate water
 masses and origins, however, this data does not exist at sufficient density
 and coverage to be informative enough to merit the additional computational
 load (at present).
 Instead, the residuals errors are modeled locally in each subdomain as
 a weighted timeseries with two Fourier harmonics in time (an interannual
 and a subannual/seasonal component).
 The weights are determined from the inverse squared distance from each
 statistical node 
\begin_inset Formula $h_{m}$
\end_inset

.
 Additional penalized thin-plate spline smooth terms for local depth and
 position are used to resolve local spatial trends and aliasing to third
 order or less (via shrinkage).
 Temporal predictions at each spatial datum are then used to 
\begin_inset Quotes eld
\end_inset

augment
\begin_inset Quotes erd
\end_inset

 the modeling of the spatial processes 
\begin_inset Formula $\varphi_{s,t|m}^{*}$
\end_inset

 which are treated independently for each time slice as a 
\series bold
Gaussian process
\series default
.
 The temporal autocorrelation is, therefore, carried only indirectly by
 the individual temporal processes centered at each spatial datum.
 For faster computations, a Fast Fourier Transform (FFT) based convolution
 method is used to approximate the spatial Gaussian process.
 The model specification is, therefore: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}Y_{s,t} & = & F(\text{identity})+\varphi_{s,t},\\
\varphi_{s,t} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}),\\
\varphi_{s,t|m} & = & f_{m}(\text{interannual,seasonal,northing,easting,depth})+\zeta_{s,t|m}\\
\zeta_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\zeta|m}^{2}),\\
\varphi_{s,t|m}^{*} & = & \omega_{s,t|m}+\varepsilon_{s,t|m},\\
\omega_{s,t|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{t|m}=\{\nu_{t|m},\phi_{t|m},\sigma_{t|m}\})),\\
\varepsilon_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
The temperature data originate from a number of different sources, including
 the snow crab survey, groundfish survey, AZMP survey, FSRS survey, scallop
 survey and many other opportunistic samples maintained and kindly provided
 by Roger Petitpas (OSD, DFO).
 It can be parameterized as:
\end_layout

\begin_layout Quotation

\size scriptsize
year.assessment = 2017
\end_layout

\begin_layout Quotation

\size scriptsize
ram_required_main_process = 22 # GB
\end_layout

\begin_layout Quotation

\size scriptsize
ram_required_per_process = 4 # GB in 2017, for GAM
\end_layout

\begin_layout Quotation

\size scriptsize
ncpu = min( parallel::detectCores(), floor( (ram_local()-ram_required_main_proce
ss) / ram_required_per_process ) )
\end_layout

\begin_layout Quotation

\size scriptsize
p = aegis::aegis_parameters(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
year.assessment=year.assessment, 
\end_layout

\begin_layout Quotation

\size scriptsize
DS = "temperature",
\end_layout

\begin_layout Quotation

\size scriptsize
data_root = project.datadirectory( "aegis", "temperature" ),
\end_layout

\begin_layout Quotation

\size scriptsize
spatial.domain = "canada.east", # default
\end_layout

\begin_layout Quotation

\size scriptsize
DATA = 'temperature.db( p=p, DS="stmv.inputs" )',
\end_layout

\begin_layout Quotation

\size scriptsize
additional.data=c("groundfish", "snowcrab", "USSurvey_NEFSC", "lobster"),
\end_layout

\begin_layout Quotation

\size scriptsize
pres_discretization_temperature = 1 / 100, # 1==p$pres; controls resolution
 of data prior to modeling (km ..
 ie 100 linear units smaller than the final discretization pres)
\end_layout

\begin_layout Quotation

\size scriptsize
yrs = 1950:year.assessment,
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_dimensionality="space-year-season",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelengine = "none",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelformula = "none", # only marginally useful ..
 consider removing it and use "none",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_family ="none",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_modelengine = "twostep" ,
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_twostep_time = "gam",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_modelformula_time = formula( paste(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
't', '~ s(yr, k=12, bs="ts") + s(cos.w, k=3, bs="ts") + s(sin.w, k=3, bs="ts")
 ',
\end_layout

\begin_layout Quotation

\size scriptsize
'+ s( cos.w, sin.w, yr, k=50, bs="ts")',
\end_layout

\begin_layout Quotation

\size scriptsize
'+ s(log(z), k=3, bs="ts") '
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
) ) ,
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_twostep_space = "fft", # everything else is too slow ...
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_fft_filter="spatial.process", # fft==spatial.process, krige (very slow),
 lowpass, lowpass_spatial.process
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_model_distanceweighted = TRUE,
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_gam_optimizer=c("outer", "bfgs"),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_variogram_method = "gstat",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_eps = 0.1, # distance units for eps noise to permit mesh gen for boundaries
 (INLA-based methods)
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_rsquared_threshold = 0, # lower threshold ..
 not used if twostep method
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_statsgrid = 10, # resolution (km) of data aggregation (i.e.
 generation of the ** statistics ** )
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_scale = 30, # km ...
 approx guess of 95% AC range
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_max = 50,
\end_layout

\begin_layout Quotation

\size scriptsize
sampling = c( 1, 1.25 ), # fractions of distance scale and n.min to try when
 insufficient data
\end_layout

\begin_layout Quotation

\size scriptsize
n.min = 20*(year.assessment-1950), # ~ 1000 min number of data points req
 before attempting to model timeseries in a localized space
\end_layout

\begin_layout Quotation

\size scriptsize
n.max = 5000, # no real upper bound..
 just speed / RAM limits
\end_layout

\begin_layout Quotation

\size scriptsize
clusters = rep("localhost", ncpu)
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
)
\end_layout

\begin_layout Quotation

\size scriptsize
stmv( p=p, runmode="interpolate")
\end_layout

\begin_layout Quotation

\size scriptsize
temperature.db( p=p, DS="predictions.redo" ) # 10 min
\end_layout

\begin_layout Quotation

\size scriptsize
temperature.db( p=p, DS="stmv.stats.redo" ) # warp to sub grids
\end_layout

\begin_layout Subsection
Example 3: inseparable spatiotemporal model of snow crab habitat and abundance
 
\end_layout

\begin_layout Standard
The snow crab estimation process uses the above and other covariates interpolate
d to the same continuous spatial support of the snow crab assessment.
 This is required to refine predictions of snow crab abundance and habitat
 while avoiding issues of bias due to aliasing (also known as 
\begin_inset Quotes qld
\end_inset

upscaling
\begin_inset Quotes qrd
\end_inset

 and 
\begin_inset Quotes qld
\end_inset

downscaling
\begin_inset Quotes qrd
\end_inset

 issues).
 Some of these covariates change on geological time scales relative to the
 timescale of the biological and ecological processes of interest and so
 can be considered functionally a 
\begin_inset Quotes eld
\end_inset

pure
\begin_inset Quotes erd
\end_inset

 spatial model (though of course they are not truly static).
 And others that are more biological in nature vary at similar or even shorter
 time scales and so require a temporal component.
 Here we detail some of these core data sources and their model assumptions
 in the context of the temporal autocorrelation scale of snow crab abundance
 in the Maritimes Region of Canada.
 
\end_layout

\begin_layout Standard
Additional covariates that express the ecosystem state at a given time and
 location (
\begin_inset Quotes eld
\end_inset

indicators
\begin_inset Quotes erd
\end_inset

) are informative in delineating spatiotemporal processes that are structured
 from those that are random.
 Their model formulation is similar in that they follow a similar model
 structure with temporal effects nested in spatial subdomains and the use
 of link functions in a Generalized Linear Model/Generalized Additive Model
 setting where the covariates used to model these indicators rely upon spatial
 predictions of depth and substrate grain size and the spatial derivatives
 of the former (slope and curvature).
 The spatiotemporal error process is modeled locally in each subdomain as
 a space-time 
\begin_inset Quotes eld
\end_inset

inseparable
\begin_inset Quotes erd
\end_inset

 model, using time-varying covariates related to bottom temperature variations
 and associated statistics:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}g(Y_{s,t}) & = & F(\text{depth, slope, curvature, substrate grainsize})+\varphi_{s,t}\\
\varphi_{s,t} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}),\\
\varphi_{s,t|m} & = & f_{m}(\text{interannual,seasonal,northing,easting,depth})+\zeta_{s,t|m}\\
\zeta_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\zeta|m}^{2}),\\
\varphi_{s,t|m}^{*} & = & \omega_{s,t|m}+\varepsilon_{s,t|m},\\
\omega_{s,t|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{t|m}=\{\nu_{t|m},\phi_{t|m},\sigma_{t|m}\})),\\
\varepsilon_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
For the estimation of habitat preferences and the creation of species distributi
on maps that rely upon presence-absence data.
 The data 
\begin_inset Formula $Y$
\end_inset

 are assumed to come from a Bernoulli binomial process with a logit link
 function 
\begin_inset Formula $g(\cdot)$
\end_inset

: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}\text{logit}(Y_{s,t}) & = & F(\text{depth, slope, curvature, substrate grainsize})+\varphi_{s,t}\\
\varphi_{s,t} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}),\\
\varphi_{s,t|m} & = & f_{m}(\text{ecosystem indicators})+\zeta_{s,t|m}\\
\zeta_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\zeta|m}^{2}),\\
\varphi_{s,t|m}^{*} & = & \omega_{s,t|m}+\varepsilon_{s,t|m},\\
\omega_{s,t|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{t|m}=\{\nu_{t|m},\phi_{t|m},\sigma_{t|m}\})),\\
\varepsilon_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
The above model is parameterized as:
\end_layout

\begin_layout Quotation

\size scriptsize
year.assessment = 2017
\end_layout

\begin_layout Quotation

\size scriptsize
p = bio.snowcrab::load.environment( year.assessment=year.assessment )
\end_layout

\begin_layout Quotation

\size scriptsize
p = snowcrab_stmv( p=p, DS="parameters",
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
variables=list(Y="snowcrab.large.males_presence_absence"),
\end_layout

\begin_layout Quotation

\size scriptsize
selection=list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
type = "presence_absence",
\end_layout

\begin_layout Quotation

\size scriptsize
biologicals = list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
sex=0, # male
\end_layout

\begin_layout Quotation

\size scriptsize
mat=1, # do not use maturity status in groundfish data as it is suspect
 ..
\end_layout

\begin_layout Quotation

\size scriptsize
spec_bio=bio.taxonomy::taxonomy.recode( from="spec", to="parsimonious", tolookup=2
526 ),
\end_layout

\begin_layout Quotation

\size scriptsize
len= c( 95, 200 )/10, # mm -> cm ; aegis_db in cm
\end_layout

\begin_layout Quotation

\size scriptsize
ranged_data="len"
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
),
\end_layout

\begin_layout Quotation

\size scriptsize
survey=list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
drop.groundfish.data=TRUE # esp from 1970 to 1999 measurement of invertebrates
 was sporatic ..
 zero-values are dropped as they are unreliable
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
)
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
),
\end_layout

\begin_layout Quotation

\size scriptsize
DATA = 'snowcrab_stmv( p=p, DS="stmv_inputs" )',
\end_layout

\begin_layout Quotation

\size scriptsize
aegis_project_datasources = c("speciescomposition" ),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_family = binomial( link="log" ),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelengine ="gam",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_stmv_global_modelformula = formula( paste(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
' snowcrab.large.males_presence_absence ~ s(t, k=3, bs="ts") + s(tmean.climatology,
 k=3, bs="ts") + s(tsd.climatology, k=3, bs="ts") ',
\end_layout

\begin_layout Quotation

\size scriptsize
' + s( log(z), k=3, bs="ts") + s( log(dZ), k=3, bs="ts") + s( log(ddZ),
 k=3, bs="ts") ',
\end_layout

\begin_layout Quotation

\size scriptsize
' + s(log(substrate.grainsize), k=3, bs="ts") + s(pca1, k=3, bs="ts") + s(pca2,
 k=3, bs="ts") ' )),
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
stmv_local_modelengine = "twostep",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_twostep_space = "gam", # fft==spatial.process, krige (very slow), lowpass,
 lowpass_spatial.process
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_modelformula_space = formula( paste(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
'snowcrab.large.males_abundance', '~ s(log(z), k=3, bs="ts") + s(plon, k=3,
 bs="ts") + s(plat, k=3, bs="ts") + s( log(z), plon, plat, k=27, bs="ts")
 ') ),
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
stmv_twostep_time = "gam",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_modelformula_time = formula( paste(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
'snowcrab.large.males_abundance', ' ~ s(yr, k=10, bs="ts") + s(cos.w, k=3,
 bs="ts") + s(sin.w, k=3, bs="ts") ',
\end_layout

\begin_layout Quotation

\size scriptsize
'+ s( cos.w, sin.w, yr, k=45, bs="ts")') ),
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
stmv_gam_optimizer=c("outer", "bfgs"),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_statsgrid = 2, # resolution (km) of data aggregation (i.e.
 generation of the ** statistics ** ),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_scale = 50
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
)
\end_layout

\begin_layout Quotation

\size scriptsize
stmv( p=p, runmode=c("globalmodel", "interpolate" ) ) # no global_model
 and force a clean restart
\end_layout

\begin_layout Quotation

\size scriptsize
snowcrab_stmv( p=p, DS="predictions.redo" ) # warp predictions to other grids
\end_layout

\begin_layout Quotation

\size scriptsize
snowcrab_stmv( p=p, DS="stmv.stats.redo" ) # warp stats to other grids
\end_layout

\begin_layout Standard
For the estimation of abundance, the positive valued data 
\begin_inset Formula $Y$
\end_inset

 are assumed to come from a lognormal process: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}\text{log}(Y_{s,t}) & = & F(\text{depth, slope, curvature, substrate grainsize})+\varphi_{s,t}\\
\varphi_{s,t} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}),\\
\varphi_{s,t|m} & = & f_{m}(\text{ecosystem indicators})+\zeta_{s,t|m}\\
\zeta_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\zeta|m}^{2}),\\
\varphi_{s,t|m}^{*} & = & \omega_{s,t|m}+\varepsilon_{s,t|m},\\
\omega_{s,t|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{t|m}=\{\nu_{t|m},\phi_{t|m},\sigma_{t|m}\})),\\
\varepsilon_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
The parametrization of the above model is as follows:
\end_layout

\begin_layout Quotation

\size scriptsize
year.assessment = 2017
\end_layout

\begin_layout Quotation

\size scriptsize
p = bio.snowcrab::load.environment( year.assessment=year.assessment )
\end_layout

\begin_layout Quotation

\size scriptsize
# 11 hrs with these settings,
\end_layout

\begin_layout Quotation

\size scriptsize
p = snowcrab_stmv( p=p, DS="parameters",
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
variables=list(Y="snowcrab.large.males_abundance"),
\end_layout

\begin_layout Quotation

\size scriptsize
sselection=list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
type = "abundance",
\end_layout

\begin_layout Quotation

\size scriptsize
biologicals=list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
sex=0, # male
\end_layout

\begin_layout Quotation

\size scriptsize
mat=1, # do not use maturity status in groundfish data as it is suspect
 ..
\end_layout

\begin_layout Quotation

\size scriptsize
spec_bio=bio.taxonomy::taxonomy.recode( from="spec", to="parsimonious", tolookup=2
526 ),
\end_layout

\begin_layout Quotation

\size scriptsize
len= c( 95, 200 )/10, # mm -> cm ; aegis_db in cm
\end_layout

\begin_layout Quotation

\size scriptsize
ranged_data="len"
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
),
\end_layout

\begin_layout Quotation

\size scriptsize
survey=list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
drop.groundfish.data=TRUE # esp from 1970 to 1999 measurement of invertebrates
 was sporatic ..
 zero-values are dropped as they are unreliable
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
)
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
DATA = 'snowcrab_stmv( p=p, DS="stmv_inputs" )',
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_Y_transform =list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
transf = function(x) {x/6675} ,
\end_layout

\begin_layout Quotation

\size scriptsize
invers = function(x) {x*6675}
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
), # transform data to unit interval to stabilize variance and speed up
 convergence
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelengine ="gam",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_family = gaussian(link="log"),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelformula = formula( paste(
\end_layout

\begin_layout Quotation

\size scriptsize
'snowcrab.large.males_abundance', '~ s(t, k=3, bs="ts") + s(tmean.climatology,
 k=3, bs="ts") + s(tsd.climatology, k=3, bs="ts") ',
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
' + s( log(z), k=3, bs="ts") + s( log(dZ), k=3, bs="ts") + s( log(ddZ),
 k=3, bs="ts") ',
\end_layout

\begin_layout Quotation

\size scriptsize
' + s(log(substrate.grainsize), k=3, bs="ts") + s(pca1, k=3, bs="ts") + s(pca2,
 k=3, bs="ts") ' )), # no space
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
stmv_local_modelengine = "twostep",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_twostep_time = "gam",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_modelformula_time = formula( paste(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
'snowcrab.large.males_abundance', '~ s(yr, k=10, bs="ts") + s(cos.w, k=3, bs="ts")
 + s(sin.w, k=3, bs="ts") ',
\end_layout

\begin_layout Quotation

\size scriptsize
' + s(cos.w, sin.w, yr, bs="ts", k=20) ',
\end_layout

\begin_layout Quotation

\size scriptsize
' + s(plon, k=3, bs="ts") + s(plat, k=3, bs="ts") + s(plon, plat, k=20,
 bs="ts") ' ) ),
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
stmv_twostep_space = "fft", # fft==spatial.process, krige (very slow), lowpass,
 lowpass_spatial.process
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_fft_filter="spatial.process", # fft==spatial.process, krige (very slow),
 lowpass, lowpass_spatial.process
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_model_distanceweighted = TRUE,
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_gam_optimizer=c("outer", "bfgs") ,
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_variogram_method = "gstat",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_statsgrid = 2, # resolution (km) of data aggregation (i.e.
 generation of the ** statistics ** )
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_scale = 50
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
)
\end_layout

\begin_layout Quotation

\size scriptsize
# range( INP$snowcrab.large.males_abundance )
\end_layout

\begin_layout Quotation

\size scriptsize
# [1] 14.3 6675.0
\end_layout

\begin_layout Quotation

\size scriptsize
# o = snowcrab_stmv(p=p, DS="stmv_inputs" ) # create fields for
\end_layout

\begin_layout Quotation

\size scriptsize
stmv( p=p, runmode=c("globalmodel", "interpolate" ) ) # for a clean start
\end_layout

\begin_layout Quotation

\size scriptsize
# stmv( p=p, runmode=c("globalmodel", "interpolate" ), use_saved_state=TRUE
 ) # for a restart ..
 not working?
\end_layout

\begin_layout Quotation

\size scriptsize
# if (really.finished) stmv_db( p=p, DS="cleanup.all" )
\end_layout

\begin_layout Quotation

\size scriptsize
snowcrab_stmv( p=p, DS="predictions.redo" ) # warp predictions to other grids
 (if any)
\end_layout

\begin_layout Quotation

\size scriptsize
snowcrab_stmv( p=p, DS="stmv.stats.redo" ) # warp stats to other grids (if
 any)
\end_layout

\begin_layout Section
References and useful papers
\end_layout

\begin_layout Standard
Banerjee, S., Carlin, B.
 P., and Gelfand, A.
 E..
 2004.
 Hierarchical Modeling and Analysis for Spatial Data.
 Monographs on Statistics and Applied Probability.
 Chapman and Hall/CRC.
\end_layout

\begin_layout Standard
Fotheringham, A.
 S., Brunsdon, C., and Charlton, M.
 E.
 (2002).
 Geographically Weighted Regression: The Analysis of Spatially Varying Relations
hips.
 Wiley, Chichester.
\end_layout

\begin_layout Standard
Hengl, T., Heuvelink, G.B.M., and Stein, A.
 2004.
 A generic framework for spatial prediction of soil variables based on regressio
n-kriging.
 Geoderma 120: 75-93.
\end_layout

\begin_layout Standard
Huang, H.-C., and Hsu, N.-J.
 2004.
 Modeling transport effects on ground-level ozone using a non-stationary
 space-time model.
 Environmetrics 15 (3), 251–268.
\end_layout

\begin_layout Standard
Kostylev, Vladimir and Hannah, Charles.
 2007.
 Process-driven characterization and mapping of seabed habitats.
 Special Paper - Geological Association of Canada.
 47: 171-184.
 
\end_layout

\begin_layout Standard
Lindgren, F., Rue, H., and Lindstrom, J.
 2011.
 An explicit link between Gaussian fields and Gaussian Markov random fields:
 the stochastic partial differential equation approach.
 Journal of the Royal Statistical Society: Series B (Statistical Methodology)
 73: 423–498.
 
\end_layout

\begin_layout Standard
Sigrist, F., Künsch, H.
 R., and Stahel, W.
 A.
 2012.
 A dynamic nonstationary spatio-temporal model for short term prediction
 of precipitation.
 Ann.
 Appl.
 Statist.
 6: 1452–1477.
 
\end_layout

\begin_layout Standard
Sølna, K., and Switzer, P.
 .1996.
 Time trend estimation for a geographic region.
 Journal of the American Statistical Association 91: 577–589.
\end_layout

\begin_layout Standard
Wikle, C.K., and Cressie, N.
 1999.
 A dimension-reduced approach to space-time Kalman filtering.
 Biometrika 86: 815–829.
\end_layout

\begin_layout Standard
Xu, K., Wikle, C.
 K., and N.
 I.
 Fox.
 2005.
 A kernel-based spatio-temporal dynamical model for nowcasting weather radar
 reflectivities.
 Journal of the American Statistical Association 100: 1133–1144.
\end_layout

\end_body
\end_document
